from typing import List

import requests
from langchain_core.documents import Document
from pydantic import BaseModel

from config.config import configs
from prompt.prompt import REPHRASE_TEMPLATE, RESPONSE_TEMPLATE
from server.data_object.chat_history import ChatHistoryDO
from server.mapper.chat_history import search_chat_history, add_chat_history
from vector_store.pg_vector import search_documents


class ChatRequest(BaseModel):
    """
    ChatQuery schema
    """

    question: str
    chat_history: List[str] = []
    limit: int = 3


async def rephrase_llm(request: ChatRequest) -> str:
    """
    Rephrase a given question based on the chat history using a language model.

    Args:
        request (ChatRequest): Request object containing the chat history and the question to rephrase.

    Returns:
        str: The rephrased question generated by the language model.

    """
    headers = {"Content-Type": "application/json"}
    chat_history_list = []
    chat_history_str = ""
    chat_history = request.chat_history
    limit = request.limit
    if chat_history is None or len(chat_history) == 0:
        if limit > 0:
            chat_history: List[ChatHistoryDO] = await search_chat_history(limit)
            question_list = []
            for chat_record in chat_history:
                question_list.append(chat_record.query_history)
            chat_history_list = question_list
    else:
        chat_history_list = chat_history[:limit]
    if len(chat_history_list) > 0:
        chat_history_str = "\n".join(chat_history_list)
    else:
        return chat_history_str
    rephrase_template = REPHRASE_TEMPLATE.format(chat_history_str, request.question)
    data = {"model": configs.llm_model, "prompt": rephrase_template, "stream": False}
    endpoint_url = configs.endpoint_url + "api/generate"
    response = requests.post(
        endpoint_url, headers=headers, json=data, timeout=(10, 300), stream=False
    )
    response_json = response.json()
    return response_json["response"]


async def chat_llm(request: ChatRequest) -> str:
    """
    Interact with a language model to generate a response based on the user's question and relevant documents.

    Args:
        request (ChatRequest): Request object containing the user's question.

    Returns:
        str: The response generated by the language model.

    """
    headers = {"Content-Type": "application/json"}
    question = request.question
    chatHistoryDO = ChatHistoryDO(query_history=question)
    await add_chat_history(chatHistoryDO)
    docs: List[Document] = await search_documents(question)
    if len(docs) == 0:
        return "未找到有关的参考文献, 我也不确定答案是什么"
    page_content_list = []
    for doc in docs:
        page, meta = doc
        print(page.page_content)
        page_content_list.append(page.page_content)
    relate_doc_str = "\n".join(page_content_list)
    response_template = RESPONSE_TEMPLATE.format(relate_doc_str)
    data = {
        "model": configs.llm_model,
        "messages": [
            {"role": "system", "content": response_template},
            {"role": "user", "content": question},
        ],
        "stream": False,
    }
    endpoint_url = configs.endpoint_url + "api/chat"
    response = requests.post(
        endpoint_url, headers=headers, json=data, timeout=(10, 300), stream=False
    )
    response = response.json()
    result = response["message"]["content"]
    return result
